# ============================================================================
# FastFood Subspace Merging Configuration
# Supports multiple merging functions including EMA with adaptive β_t
# ============================================================================

_target_: fusion_bench.method.fastfood_merging.FastfoodSubspaceMergeAlgorithm

# ============================================================================
# Core FastFood Parameters
# ============================================================================
proj_ratio: 0.75              # Subspace compression ratio (0.0-1.0)
use_G: false                  # Use Gaussian scaling in FastFood transform
device: "cuda"                # Computation device
block_rows: 16384             # Memory management for large tensors

# ============================================================================
# Transform Type
# ============================================================================
transform_type: "srht"       # Options: srht | fwht | dct | dht | none | fastfood
                              # - srht: Subsampled Hadamard (default, recommended)
                              # - fwht: Full Hadamard (no subsampling)
                              # - dct: Discrete Cosine Transform
                              # - dht: Discrete Hartley Transform
                              # - none (or null): No projection, merge in original space (baseline)
                              # - fastfood: Original FastFood transform
# This parameter can be swept via --transform_types in the workflow/SLURM/CLI for fastfood_merging

# ============================================================================
# Adaptive Projection Size Estimation (Optional)
# ============================================================================
use_adaptive_proj_size: false # Enable adaptive projection size estimation
adaptive_proj_mode: "tensor"  # "tensor" | "layer" (scope for rank estimation and projection size computation)
                              # - tensor: per-tensor projection size (uses individual tensor dimensions)
                              # - layer: per-layer projection size (uses max dimension across layer tensors)
adaptive_proj_strategy: "rank" # "fixed" | "random" | "rank" | "layer_progressive" | "layer_group" | "layer_power_law"
                              # - fixed: m = ratio * d_last
                              # - random: m ~ U[m_min, f_max * d_last]
                              # - rank: m = beta * estimated_rank
                              # - layer_progressive: gradual scaling from start_ratio to end_ratio across layers
                              # - layer_group: fixed ratio per group (feature extraction vs head)
                              # - layer_power_law: power-law redistribution with global budget (B = global_ratio * sum(dims))
adaptive_proj_m_min: 8       # Minimum projection size
adaptive_proj_f_max: 1.0      # Maximum fraction of d_last
adaptive_proj_pow2: false      # Round to power-of-2
adaptive_proj_pow2_mode: "ceil" # "ceil" | "floor" | "nearest"
adaptive_proj_beta: 2.5       # For "rank" strategy: m = beta * estimated_rank
adaptive_proj_seed: null      # Random seed for "random" strategy (null = use global random)

# Layer Progressive Strategy Parameters (for adaptive_proj_strategy="layer_progressive")
adaptive_proj_start_ratio: 0.1  # Starting ratio (0.0-1.0) for first layer
adaptive_proj_end_ratio: 1.0    # Ending ratio (0.0-1.0) for last layer
adaptive_proj_growth_mode: "linear" # "linear" | "exponential"
                               # - linear: ratio(t) = start + t * (end - start)
                               # - exponential: ratio(t) = start * (end/start)^t
                               # where t ∈ [0,1] is normalized layer position
                               # Final projection size: m = ratio * d_last

# Layer Group Strategy Parameters (for adaptive_proj_strategy="layer_group")
adaptive_proj_group_boundary: 5    # Layer index separating feature extraction from head (0-based)
adaptive_proj_feature_ratio: 0.3   # FIXED projection ratio for feature extraction layers (0.0-1.0)
                               # Applied to layers 0 to boundary-1
adaptive_proj_head_ratio: 0.8      # FIXED projection ratio for head layers (0.0-1.0)
                               # Applied to layers >= boundary
                               # Note: These are FIXED ratios per group, not adaptive
                               # Final projection size: m = group_ratio * d_last
                               # Compatible with ALL adaptive_proj_mode and subspace_scope settings

# Global Power-Law Strategy Parameters (for adaptive_proj_strategy="global_power_law")
adaptive_proj_global_ratio: 0.25   # Overall compression budget (average ratio across all layers, 0.0-1.0)
                               # This maintains a global projection capacity budget B = global_ratio * sum(all_dims)
adaptive_proj_power_law_alpha: 0.85 # Power-law exponent for dimension-aware redistribution (0.7-0.95 typical)
                               # alpha < 1: Larger layers compressed more, smaller layers less (default: 0.85)
                               # alpha = 1: Uniform ratio (equivalent to fixed strategy)
                               # alpha > 1: Larger layers compressed less, smaller layers more
                               # Formula: m_i = B * (d_i^alpha) / sum(d_j^alpha)
                               # This ensures average compression = global_ratio while adapting to layer sizes

# ============================================================================
# Weight Matching Preprocessing (Optional - Git Re-Basin)
# ============================================================================
use_weight_matching: false    # Enable weight matching to align neurons before merging
weight_matching_max_iter: 100 # Maximum iterations for weight matching optimization
weight_matching_seed: 0       # Random seed for reproducibility
weight_matching_verbose: true # Print progress during weight matching
weight_matching_input_shapes: # Custom input shapes for permutation spec generation
  - [1, 3, 224, 224]          # Default: vision model (batch=1, RGB, 224x224)
                                # For NLP: [[1, 512]] or similar

# ============================================================================
# Subspace Configuration
# ============================================================================
subspace_scope: "global"     # per_tensor | per_flat_tensor | layer | global
                              # - per_tensor: row-wise projection (standard)
                              # - per_flat_tensor: flatten 2D to (out*in), one projection
                              # - layer: layer-wise shared projection
                              # - global: single global projection for all params
merge_where: "subspace"       # subspace | postlift

# ============================================================================
# Merging Strategy
# ============================================================================
merge_func: "signmax"         # sum | mean | max | signmax | ema | ties_sum | ties_mean | ties_max
align_mode: "none"            # none | ties | tadrop

# ============================================================================
# EMA Parameters (Active when merge_func="ema")
# ============================================================================
ema_task_order: "custom"       # given | random | cosine_similarity | custom
ema_gamma: 2.0 #1.2                # Sigmoid scaling factor (0.5-2.0)
ema_w_c: 0.8 #0.6                  # Cosine alignment weight (0.0-1.0)
ema_w_s: 0.2 #0.4                  # Scale ratio weight (0.0-1.0, w_c + w_s = 1.0)
ema_custom_order: 
  - "SUN397"
  - "Stanford-Cars" 
  - "DTD"
  - "GTSRB"
  - "SVHN"
  - "MNIST"
  - "RESISC45"
  - "EuroSAT"

# ============================================================================
# TIES Merging Options (when merge_func starts with "ties_")
# Note: TIES implementation skips the Trim phase (no parameter pruning)
# and focuses on Elect phase (sign resolution) + Disjoint Merge phase
# ============================================================================
# ties_sum:  Elect majority sign per parameter, then sum agreeing task vectors
# ties_mean: Elect majority sign per parameter, then mean of agreeing task vectors  
# ties_max:  Elect majority sign per parameter, then max magnitude with correct sign

# ============================================================================
# Advanced Alignment Options
# ============================================================================
ties_trim_pct: 0.0            # TIES pruning percentage (0.0-1.0)
tadrop_tau: 0.0               # Task Arithmetic dropout threshold

# ============================================================================
# TSV-Style Linear/Non-Linear Separation
# ============================================================================
only_project_linear: false    # If true, only 2D tensors are projected; 1D tensors merged with mean in original space
                              # This mimics TSV behavior: linear layers (weights) use subspace, non-linear (biases, norms) use mean

# ============================================================================
# Embedding Layer Control
# ============================================================================
project_embeddings: true      # If false, embedding layers are excluded from projection and merged in original space
                              # Embedding layers are detected by name patterns: position_embedding, pos_embed, patch_embed, 
                              # token_embedding, cls_token, mask_token, decoder_embed, text_projection, etc.
                              # Use case: Embeddings often have distinct representations that may not benefit from projection
                              # This parameter is complementary to only_project_linear
                              # - only_project_linear=false + project_embeddings=false: Embeddings merged in original space
                              # - only_project_linear=true + project_embeddings=false: Embeddings merged in original space (if 2D)
                              # Default: true (all layers projected, maintains backward compatibility)

# ============================================================================
# Post-processing Options
# ============================================================================
use_pareto: false             # Apply Pareto frontier optimization
use_rescale: false            # Rescale merged parameters
weights: null                 # Task importance weights [w1, w2, ..., wN]
scale: 1.0                    # Global scaling factor

# ============================================================================
# Integrated Analysis Options
# ============================================================================
run_analysis: false          # Whether to run analysis after merging (disabled for SLURM workflow control)
analysis_methods: [merged_task_vector, task_vector_similarity, task_vector_layer]
          # List of analysis methods to run
                             # Options: merged_task_vector, task_vector_similarity, task_vector_layer
analysis_output_path: null    # Path for analysis outputs (uses fabric logger if null)

# ============================================================================
# Task Arithmetic Reconstruction mode
# ============================================================================
use_task_arithmetic_reconstruction: false
task_arithmetic_scaling: 1.0  # Standard TA scaling factor
report_reconstruction_error: true  # Report reconstruction error after projection

# ============================================================================
# LiNeS (Layer Scaling) Parameters
# ============================================================================
use_lines: false              # Enable LiNeS layer-wise progressive scaling
lines_num_blocks: null        # Number of residual blocks (null = auto-detect: 12 for ViT-B, 24 for ViT-L)
lines_alpha: null             # Minimum scaling factor (null = auto-compute or use beta)
                              # - If lines_auto_alpha=true: alpha = (norm_summed_tvs / norm_merged_tv) * (1 / num_tasks)
                              # - If lines_auto_alpha=false and lines_alpha=null: alpha = lines_beta
lines_beta: 1.0               # Maximum additional scaling (creates gradient from early to late layers)
                              # Scaling formula: scale(layer) = alpha + beta * (layer_idx / (num_blocks - 1))
                              # Example: alpha=0.2, beta=0.8 → scales from 0.2 (early layers) to 1.0 (late layers)
lines_auto_alpha: true        # Auto-compute alpha from task vector norms (recommended for multi-task)
                              # When true: alpha adapts to the merging configuration
                              # When false: use manual lines_alpha or default to lines_beta

# LiNeS Explanation:
# - LiNeS applies layer-depth-dependent scaling to merged task vectors
# - Early layers (general features): lower scaling → preserve pretrained knowledge
# - Later layers (task-specific): higher scaling → preserve task adaptations
# - This reduces catastrophic forgetting and improves multi-task merging
# - Compatible with all merge functions (sum, mean, ties, ema, signmax, etc.)
# - Reference: "LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging"
